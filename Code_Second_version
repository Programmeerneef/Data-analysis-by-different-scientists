#All dataframes are now read in correctly


#CODE DOES NOT WORK BUT DATA IS READ IN CORRECTLY


#Comparing the results from data-analysis performed by different scientists
import os
import sys
import numpy as np
from colorama import Fore
import scipy as sp  #Welch's t-test (t-test for independent samples, does not assume same var) and F-test (var1==var2?)
from scipy import stats
import pandas as pd
'''
for line in fileinput.input(file, inplace=1):
    if "," in line:
       line=line.replace(",",".")
       sys.stdout.write(line)
'''

def Clean_Data(path):            #The calibration text file makes no sense without cleaning it a bit
    for root, dirs, files, in os.walk(path):    #Entire file is pre-cleaned before reading it in
        for filename in files:
            file = open(os.path.join(root, filename), "r+")
            if (filename.endswith("txt")):
                pass
            elif (filename.endswith("csv")):
                for row in file:
                    for character in row:
                        if (character==","):        #Convert , to . since python interprets . as , (American notation)
                            file.write(".")
            file.close()
    return Clean_Data



def Read_In_Data(path):                #Appends every file (only csv and txt) into a list
    Data = []
    for root, dirs, files, in os.walk(path):
        for filename in files:
            file=open(os.path.join(root,filename),"r")
            if (filename.endswith("txt") or filename.endswith("csv")):
                Data.append(filename)
                file.close()
    Data=sorted(Data)          #Alphabetically sort the filenames
    print(Fore.LIGHTBLACK_EX + "Filenames: ", Data)
    return Data

def Generate_Dictionaries(Data,path):
    Dictionaries=[]               #List containing a dictionary for each file
    for filename in Data:             #Append files and corresponding data as dictionary to Dictionaries list
        print("filename:", filename)
        for root, dirs, files in os.walk(path):
            for name in files:
                if (filename == name):
                    filepath=os.path.join(path, filename)
                    file = open(os.path.join(root, filename), "r")
                    print("path:", filepath)
                    print("Reading in Dataset!")
                    if filename.endswith("txt"):
                        content=pd.read_csv(file,decimal=".", skip_blank_lines=True, on_bad_lines='warn', header=None, dtype=float, delimiter='\s+', skiprows=4, usecols=[5,7])
                        content = content.to_numpy()

                    if "outcome" in filename:
                        print(Fore.RED + "outcome in filename!!!!!!!!!!!")
                        content = pd.read_csv(file, decimal=".", sep="\t|,|\s+", skip_blank_lines=True, on_bad_lines='warn',header=None, skiprows=1, usecols=[0,1], dtype=str)
                        content = content.fillna(value=np.nan)
                        cols = content.columns
                        content[cols] = content[cols].apply(pd.to_numeric, errors='coerce')       #replacing strings/non-numeric values to np.nan
                        content = content.to_numpy()

                    elif "De_integral_overview" in filename:
                        print(Fore.RED + "De_integral_overview in filename!!!!!!!!!!!")
                        content = pd.read_csv(file, decimal=",", sep="\t|s+", skip_blank_lines=True,on_bad_lines='warn', header=None, skiprows=1,index_col=0, usecols=[2,3,4,5,6,7,8,9,10,11,12,13,14,15], dtype=str)
                        content = content.fillna(value=np.nan)
                        cols = content.columns
                        content[cols] = content[cols].apply(pd.to_numeric, errors='coerce')
                        content = content.to_numpy()

                    elif "integral" in filename:
                        print(Fore.RED + "integral in filename!!!!!!!!!!!")
                        content = pd.read_csv(file, decimal=",", sep="\t|\s+", skip_blank_lines=True, on_bad_lines='warn',header=None, skiprows=1, index_col=0)
                        #del content[content.columns[0:3]]
                        content = content.iloc[:,3:]
                        cols = content.columns
                        content[cols] = content[cols].apply(pd.to_numeric, errors='coerce')        #Replacing one value that is read in weirdly to np.nan
                        #content.replace(",",".")
                        #content.astype(float)
                        content = content.to_numpy()

                    elif filename.endswith("csv"):
                        content = pd.read_csv(file, decimal=",", sep="\t", skip_blank_lines=True, on_bad_lines='warn',header=None, skiprows=1, index_col=0)
                        content = content.to_numpy()

                    Dataset={'name': filename, 'Dataset': content}
                    print(Fore.BLACK + "Dataset: ", Dataset['Dataset'])
                    Dictionaries.append(Dataset)  # Generate numpy arrays from csv here
    return Dictionaries

def Compare_Data(Dictionaries1, Dictionaries2):            #Check if the amount of files to be compared is equal
    if (len(Dictionaries1)==len(Dictionaries2)):
        return True
    else:
        return False

def Compare_Datapoints(Dictionaries1,Dictionaries2):  #Compares if both datasets contains the same amount of files + the same amount of datapoints
    for index in range(len(Dictionaries1)):          #amount of files should be the same so Dictionaries1=Dictionaries2
        if (Dictionaries1[index]['Dataset'].shape==Dictionaries2[index]['Dataset'].shape):
           pass
        else:
           return False
    return True


def Calculate_Results(Dictionaries,Data):                   #Calculates quick and easily interpretable comparison results
    for index in range(len(Data)):
        print("results filename: ", Dictionaries[index]['name'])
        datamatrix= Dictionaries[index]['Dataset']
        average= np.nanmean(datamatrix, axis=0) #Calculate variances, averages, stdevs and medians for each column
        stdev = np.nanstd(datamatrix, axis=0)
        variance=np.nanvar(datamatrix,axis=0)
        median = np.nanmedian(datamatrix, axis=0)
        Results_File=[average, stdev, variance, median]     #store column-results in list + append all columns for one file
        Results_File=np.array(Results_File)
        Dictionaries[index]['Results Dataset'] = Results_File
    return Dictionaries


def Calculate_Statistical_Results(Dictionary1, Dictionary2,Data):        #Calculates F-test t-test, results stored in Dictionary1
    for index in range(len(Data)):
        print("Statistical t-Tests filename: ", Dictionary1[index]['name'])
        datamatrix1= Dictionary1[index]['Dataset']
        print("shape: ", datamatrix1.shape)
        datamatrix2= Dictionary2[index]['Dataset']
        for column in range(datamatrix1.shape[1]):
             print("column", column)
             Results_ttest = [sp.stats.ttest_ind(datamatrix1,datamatrix2,axis=column, equal_var=False, alternative='two-sided', nan_policy='omit')]   # 2-sided Welch test
             All_Results_File = []
             All_Results_File=All_Results_File.append([Results_ttest])
        Dictionary1[index]["Statistical t-Tests"]=np.array(All_Results_File)
        # Output will be something like this below:
        #Ttest_indResult(statistic=2.23606797749, pvalue=0.04170979503207)

    for index in range(len(Data)):
        print("Statistical f-Tests filename: ", Dictionary1[index]['name'])
        print("Dataset", Dictionary1[index]['Dataset'])
        datamatrix1= Dictionary1[index]['Dataset']
        datamatrix2= Dictionary2[index]['Dataset']
        for column in range(np.shape(datamatrix1)[1]):
            f = np.var(datamatrix1, ddof=1, axis=column) / np.var(datamatrix2, ddof=1, axis=column)  # calculate F test statistic
            if (f>=1):
               dfn = datamatrix1.shape[1] - 1  # define degrees of freedom numerator
               dfd = datamatrix2.shape[1] - 1  # define degrees of freedom denominator
               p = 1 - sp.stats.f.cdf(f, dfn, dfd)  # find p-value of F test statistic
               All_Results_File = []
               All_Results_File = All_Results_File.append([p])
               Dictionary1[index]["Statistical f-Tests"] = np.array(p)
               np.array(p)
            else:
               dfn = datamatrix1.shape[1] - 1  # define degrees of freedom numerator
               dfd = datamatrix2.shape[1] - 1  # define degrees of freedom denominator
               p = 1 - sp.stats.f.cdf(f, dfn, dfd)  # find p-value of F test statistic
               All_Results_File = []
               All_Results_File = All_Results_File.append([p])
            Dictionary1[index]["Statistical f-Tests"] = np.array(All_Results_File)
    return Dictionary1

def Interpret_Statistical_Results(Data, Dictionary1):
    print("///////////////////////////////////////T-test Results//////////////////////////////////////////////////")
    for index in range(len(Data)):
        print("/////////////////////////////////////NEW FILE/////////////////////////////////////////////////////////")
        print("P-value interpretation Filename: ", Data[index]["name"])
        datamatrix1=Dictionary1[index]['Dataset']
        for column in datamatrix1.shape[0]:
            print("COLUMN: ", column)
            pvalue_ttest=Dictionary1[index]["Statistical t-Tests"].pvalue
            if (pvalue_ttest<0.01):
                 print(Fore.GREEN + pvalue_ttest)
            elif (pvalue_ttest>0.01 and pvalue_ttest<=0.05):
                 print(Fore.YELLOW + pvalue_ttest)
            elif (pvalue_ttest>0.05 and pvalue_ttest>=0.10):
                 print(Fore.BLUE+ pvalue_ttest)
            else:
                print(Fore.RED + pvalue_ttest)

    print("///////////////////////////////////////F-test Results//////////////////////////////////////////////////")
    for index in range(len(Data)):
        print("/////////////////////////////////////NEW FILE/////////////////////////////////////////////////////////")
        print("p-value interpretation Filename:", Data[index]["name"])
        datamatrix1 = Dictionary1[index]['Dataset']
        for column in datamatrix1.shape[0]:
            print("COLUMN:", column)
            pvalue_ftest = Dictionary1[index]["Statistical f-Tests"].pvalue
            if (pvalue_ftest < 0.01):
                print(Fore.GREEN + pvalue_ftest)
            elif (pvalue_ftest > 0.01 and pvalue_ftest <= 0.05):
                print(Fore.YELLOW + pvalue_ftest)
            elif (pvalue_ftest > 0.05 and pvalue_ftest >= 0.10):
                print(Fore.BLUE + pvalue_ftest)
            elif (pvalue_ftest > 0.10):
                print(Fore.RED + pvalue_ftest)


def Compare_Results(Dictionaries1, Dictionaries2,Data):
    List_Results_Ratios=[]
    for index in range(len(Data)):      #Do numpy slicing and divide
        Results_Ratios=np.divide(Dictionaries1[index]["Results Dataset"]/Dictionaries2[index]["Results Dataset"])
        List_Results_Ratios.append(Results_Ratios)
    return List_Results_Ratios

def Format_Output_File():
    #Do something
    x=1

def Colour_Coding_Info():
    print("INFO ABOUT THE STATISTICAL TEST COLOUR SCHEMES:")
    print(Fore.RED + "Red: <90% confidence level, or more than 10% difference in average, stdev, median, variance of the files")
    print(Fore.YELLOW + "Yellow: 90% confidence level, or less than 10% difference in average, stdev, median, variance of the files")
    print(Fore.BLUE + "Blue: 95% confidence level, or less than 5% difference in average, stdev, median, variance of the files")
    print(Fore.GREEN + "Green: 99% confidence level, or less than 1% difference in average, stdev, median, variance of the files")
    print(Fore.LIGHTCYAN_EX+ "The Welch t-test is a 2-tailed t-test that checks whether the files have the same average values, whilst assuming that var1 != var2.")
    print(Fore.LIGHTCYAN_EX + "The F-test checks if both datasets have the same variance.")

def Write_Results_To_File(List_Results_Ratios, Dictionary1, Data):
    NewFile= open("ResultsComparisonScript.txt", "x")
    for index in List_Results_Ratios:          #Prints results for each file
        NewFile.write("RESULTS FILE: ", index)
        NewFile.write(str(List_Results_Ratios[index]))
        NewFile.write("STATISTICAL RESULTS FILE: ", index)    #Prints statistical results for each file
        print("Statistical t-Test")
        NewFile.write(str(Dictionary1[index]["Statistical t-Tests"]))
        print("Statistical f-Test")
        NewFile.write(str(Dictionary1[index]["Statistical f-Tests"]))
    return NewFile

if __name__ == "__main__":      #Main function executes all functions in the script until file with comparison results is generated
   Colour_Coding_Info()
   #path1 = input(Fore.LIGHTWHITE_EX + "Please paste the path that contains the directory with files: ")
   #path2 = input(Fore.LIGHTWHITE_EX + "Please paste the path that contains the directory with the files with which you want to compare: ")
   path1=r"C:\Users\Vincent2\PycharmProjects\Carbyonscript\COMPARE FILES\output Dries s0212"
   path2=r"C:\Users\Vincent2\PycharmProjects\Carbyonscript\COMPARE FILES\output selfmade s0212"
   '''Clean_Data(path1)
   Clean_Data(path2)'''
   Data1=Read_In_Data(path1)
   Data2=Read_In_Data(path2)
   Dictionary1=Generate_Dictionaries(Data1,path1)
   Dictionary2=Generate_Dictionaries(Data2,path2)

   if Compare_Data(Dictionary1,Dictionary2):
       print(Fore.GREEN +"Both datasets contain the same amount of readable files.")
   else:
       print(Fore.RED +"Datasets do not contain the same amount of readable files!!! Check if extra non-readable files were created!")
       sys.exit()
   if Compare_Data(Dictionary1,Dictionary2):
       print(Fore.GREEN + "Dataset of each file contains the same amount of datapoints.")
   else:
       print(Fore.RED + "Dataset of each file does not contain the same amount of datapoints!!!")
       sys.exit()
   Dictionary1=Calculate_Results(Dictionary1,Data1)
   Dictionary2=Calculate_Results(Dictionary2,Data2)
   Dictionary1=Calculate_Statistical_Results(Dictionary1,Dictionary2, Data1)
   Comparison=Compare_Results(Dictionary1,Dictionary2,Data2)
   Write_Results_To_File(Dictionary1, Comparison)

